{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "main() takes exactly 1 argument (0 given)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-efc0629df4cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     46\u001b[0m                 \u001b[0;32mprint\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: main() takes exactly 1 argument (0 given)"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import urllib2\n",
    "import os\n",
    "import argparse\n",
    "import sys\n",
    "import json\n",
    "\n",
    "# adapted from http://stackoverflow.com/questions/20716842/python-download-images-from-google-image-search\n",
    "\n",
    "def get_soup(url,header):\n",
    "    return BeautifulSoup(urllib2.urlopen(urllib2.Request(url,headers=header)),'html.parser')\n",
    "\n",
    "def main(args):\n",
    "\t#parser = argparse.ArgumentParser(description='Scrape Google images')\n",
    "\t#parser.add_argument('-s', '--search', default='martillo', type=str, help='search term')\n",
    "\t#parser.add_argument('-n', '--num_images', default=100, type=int, help='num images to save')\n",
    "\t#parser.add_argument('-d', '--directory', default='/home/jimmy/Curso_ML/jugando/custom_data_set', type=str, help='save directory')\n",
    "\t#args = parser.parse_args()\n",
    "\tquery = \"martillo\"\n",
    "\tmax_images = \"100\"\n",
    "\tsave_directory = '/home/jimmy/Curso_ML/jugando/custom_data_set'\n",
    "\timage_type=\"Action\"\n",
    "\tquery= query.split()\n",
    "\tquery='+'.join(query)\n",
    "\turl=\"https://www.google.co.in/search?q=\"+query+\"&source=lnms&tbm=isch\"\n",
    "\theader={'User-Agent':\"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/43.0.2357.134 Safari/537.36\"}\n",
    "\tsoup = get_soup(url,header)\n",
    "\tActualImages=[]# contains the link for Large original images, type of  image\n",
    "\tfor a in soup.find_all(\"div\",{\"class\":\"rg_meta\"}):\n",
    "\t    link , Type =json.loads(a.text)[\"ou\"]  ,json.loads(a.text)[\"ity\"]\n",
    "\t    ActualImages.append((link,Type))\n",
    "\tfor i , (img , Type) in enumerate( ActualImages[0:max_images]):\n",
    "\t    try:\n",
    "\t        req = urllib2.Request(img, headers={'User-Agent' : header})\n",
    "\t        raw_img = urllib2.urlopen(req).read()\n",
    "\t        if len(Type)==0:\n",
    "\t            f = open(os.path.join(save_directory , \"img\" + \"_\"+ str(i)+\".jpg\"), 'wb')\n",
    "\t        else :\n",
    "\t            f = open(os.path.join(save_directory , \"img\" + \"_\"+ str(i)+\".\"+Type), 'wb')\n",
    "\t        f.write(raw_img)\n",
    "\t        f.close()\n",
    "\t    except Exception as e:\n",
    "\t        print \"could not load : \"+img\n",
    "\t        print e\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
